{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a7ed56f",
   "metadata": {},
   "source": [
    "# Experiment 3: Starting to Use Dense Embeddings\n",
    "\n",
    "In this notebook, we look to start applying a dense embedding approach, pulling a pretrained dense embedding model of Sentence Transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e1263247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name is: news-aggregator\n",
      "Loaded 8604 Documents\n",
      "Loaded 8604 Judgments\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "if \"DATASET_NAME\" in os.environ:\n",
    "    DATASET_NAME = os.environ[\"DATASET_NAME\"]\n",
    "else:\n",
    "    DATASET_NAME= \"news-aggregator\"\n",
    "    \n",
    "print(f\"Dataset name is: {DATASET_NAME}\")\n",
    "\n",
    "train_catalog_df = pd.read_csv(f\"data/{DATASET_NAME}/train_catalog.csv\")\n",
    "train_queries_df = pd.read_csv(f\"data/{DATASET_NAME}/train_queries.csv\")\n",
    "val_catalog_df = pd.read_csv(f\"data/{DATASET_NAME}/val_catalog.csv\")\n",
    "val_queries_df = pd.read_csv(f\"data/{DATASET_NAME}/val_queries.csv\")\n",
    "print(f\"Loaded {len(train_catalog_df.index)} Documents\")\n",
    "print(f\"Loaded {len(train_queries_df.index)} Judgments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "df83cc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation strategy is: synonym\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation\n",
    "\n",
    "if \"AUGMENTATION\" in os.environ:\n",
    "    AUGMENTATION = os.environ[\"AUGMENTATION\"]\n",
    "else:\n",
    "    AUGMENTATION = \"synonym\"\n",
    "    \n",
    "print(f\"Augmentation strategy is: {AUGMENTATION}\")\n",
    "    \n",
    "if AUGMENTATION == \"none\":\n",
    "    pass\n",
    "elif AUGMENTATION == \"synonym\":\n",
    "\n",
    "    import nlpaug.augmenter.word as naw\n",
    "\n",
    "    aug = naw.SynonymAug(aug_src='wordnet', aug_p=0.25)\n",
    "    train_queries_df[\"input_text\"] = train_queries_df[\"input_text\"].apply(lambda x: aug.augment(x)[0])\n",
    "    val_queries_df[\"input_text\"] = val_queries_df[\"input_text\"].apply(lambda x: aug.augment(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "983f7f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Linn Energy (line of business) to Acquire US non - Core Oil colour, Gas Plus of Devon Get up and go'\n",
      " 'Linn Vim (stemma) to Acquire US non - Core Crude, Gas Assets of Devonshire Get up and go'\n",
      " 'Western Digital My Cloud EX2 Followup: Cloud Storage Simple mindedness'\n",
      " 'Western Digital My Cloud EX2 Brushup: Cloud Storage Simplicity'\n",
      " 'China central bank to aim tough on shadow financing'\n",
      " 'Communist china central coin bank to receive tough on shadow financing'\n",
      " 'Gas prices in realm ascent 2 cent this week'\n",
      " 'Gas terms in part rise 2 cents this week'\n",
      " 'Did you freeze Foster Farm chicken in March? Some be recalled'\n",
      " 'Did you suspend Foster Farm gallus gallus in March? Some being recalled'\n",
      " 'Putting a 2015 Ford hermann hueffer Mustang on Top of The Empire State Edifice'\n",
      " 'Put a 2015 Ford Mustang on Top of The Empire State Building'\n",
      " 'Norfolk Southern Shows EPS Estimates Down In Yesteryear Calendar month'\n",
      " 'Norfolk Southern Show EPS Estimates Down In Past times Month'\n",
      " 'Mathematics used to counteract squirt lag'\n",
      " 'Mathematics use to counteract jet lag'\n",
      " 'Anthony Cumia of the \" Opie and Mark anthony show \" assaulted'\n",
      " 'Susan anthony Cumia of the \" Opie and Anthony show \" assaulted'\n",
      " 'iPhone 6 Will Price Malus pumila Fans Big'\n",
      " 'iPhone 6 Will Cost Apple Fan Big']\n"
     ]
    }
   ],
   "source": [
    "print(train_queries_df.head(20)[\"input_text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "338bbeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scores': array([0., 0., 0., ..., 0., 0., 0.])}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy.random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "class RandomRanker:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, catalog_df, queries_df):\n",
    "        pass\n",
    "    \n",
    "    def prerun(self, catalog_df):\n",
    "        pass\n",
    "    \n",
    "    def get_score(self, query, catalog_df):\n",
    "        text = query[\"input_text\"]\n",
    "        return {\n",
    "            \"scores\": np.random.uniform(0,1,size=len(catalog_df))\n",
    "        }\n",
    "    \n",
    "def levenshtein_distance(word1, word2):\n",
    "    if len(word1) < len(word2):\n",
    "        return levenshtein_distance(word2, word1)\n",
    "\n",
    "    if len(word2) == 0:\n",
    "        return len(word1)\n",
    "\n",
    "    previous_row = range(len(word2) + 1)\n",
    "\n",
    "    for i, c1 in enumerate(word1):\n",
    "        current_row = [i + 1]\n",
    "\n",
    "        for j, c2 in enumerate(word2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]\n",
    "    \n",
    "\n",
    "def normalized_levenshtein_distance(word1, word2):\n",
    "    distance = levenshtein_distance(word1, word2)\n",
    "    max_length = max(len(word1), len(word2))\n",
    "    return distance / max_length\n",
    "\n",
    "    \n",
    "class LevensteinRanker:\n",
    "    def __init__(self):\n",
    "        print(\"Wanring! This is a slow ranker\")\n",
    "        pass\n",
    "    \n",
    "    def train(self, catalog_df, queries_df):\n",
    "        pass\n",
    "    \n",
    "    def prerun(self, catalog_df):\n",
    "        pass\n",
    "    \n",
    "    def get_score(self, query, catalog_df):\n",
    "        text = str(query[\"input_text\"])\n",
    "        \n",
    "        return {\n",
    "            \"scores\": catalog_df[\"text\"].apply(lambda x: -normalized_levenshtein_distance(x, text)).values\n",
    "        }\n",
    "    \n",
    "class BoWRanker:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b', lowercase=True)\n",
    "\n",
    "    def train(self, catalog_df, queries_df):\n",
    "        self.vectorizer.fit(catalog_df['text'].str.lower())\n",
    "\n",
    "    def prerun(self, catalog_df):\n",
    "        self.bow_matrix = self.vectorizer.transform(catalog_df['text'].str.lower())\n",
    "        \n",
    "    def get_score(self, query, catalog_df):\n",
    "        text = str(query[\"input_text\"]).lower()\n",
    "        query_vector = self.vectorizer.transform([text])\n",
    "        scores = (self.bow_matrix * query_vector.T).toarray()\n",
    "        return {\n",
    "            \"scores\": scores.flatten()\n",
    "        }\n",
    "    \n",
    "class TfidfRanker:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(token_pattern=r'\\b\\w+\\b', lowercase=True)\n",
    "\n",
    "    def train(self, catalog_df, queries_df):\n",
    "        self.vectorizer.fit(catalog_df['text'].str.lower())\n",
    "\n",
    "    def prerun(self, catalog_df):\n",
    "        self.tfidf_matrix = self.vectorizer.transform(catalog_df['text'].str.lower())\n",
    "        \n",
    "    def get_score(self, query, catalog_df):\n",
    "        text = str(query[\"input_text\"]).lower()\n",
    "        query_vector = self.vectorizer.transform([text])\n",
    "        scores = (self.tfidf_matrix * query_vector.T).toarray()\n",
    "        return {\n",
    "            \"scores\": scores.flatten()\n",
    "        }\n",
    "    \n",
    "class BM25Ranker:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def train(self, catalog_df, queries_df):\n",
    "        pass\n",
    "        \n",
    "    def prerun(self, catalog_df):\n",
    "        corpus = catalog_df['text'].str.lower().tolist()\n",
    "        tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "    def get_score(self, query, catalog_df):\n",
    "        text = str(query[\"input_text\"]).lower()\n",
    "        query_vector = text.split(\" \")\n",
    "        scores = self.bm25.get_scores(query_vector)\n",
    "        return {\n",
    "            \"scores\": scores\n",
    "        }\n",
    "    \n",
    "class EmbeddingRanker:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def train(self, catalog_df, queries_df, epochs=0):\n",
    "        if epochs != 0:\n",
    "            \n",
    "            # Prepare the data for training\n",
    "            examples = []\n",
    "            for _, row in queries_df.iterrows():\n",
    "                text = str(row['input_text'])\n",
    "                positive_id = row['match_id']\n",
    "                try:\n",
    "                    positive_text = catalog_df.loc[catalog_df['catalog_id'] == positive_id, 'text'].values[0]\n",
    "                    negative_ids = catalog_df.loc[catalog_df['catalog_id'] != positive_id, 'catalog_id'].sample(n=1).values\n",
    "                    negative_text = catalog_df.loc[catalog_df['catalog_id'] == negative_ids[0], 'text'].values[0]\n",
    "                    examples.append(InputExample(texts=[text, positive_text, negative_text]))\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "            print(f\"{len(examples)} Examples Found\")\n",
    "\n",
    "            train_dataloader = DataLoader(examples, shuffle=True, batch_size=16)\n",
    "            train_loss = losses.TripletLoss(self.model)\n",
    "\n",
    "            self.model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=epochs, optimizer_params={'lr': 2e-6})\n",
    "\n",
    "    def prerun(self, catalog_df):\n",
    "        self.corpus = catalog_df['text'].str.lower().tolist()\n",
    "        self.corpus_embeddings = self.get_embeddings(self.corpus)\n",
    "\n",
    "    def get_score(self, query, catalog_df):\n",
    "        query_embedding = self.get_embeddings([query[\"input_text\"]])\n",
    "        scores = cosine_similarity(query_embedding, self.corpus_embeddings)\n",
    "        return {\n",
    "            \"scores\": scores.flatten()\n",
    "        }\n",
    "\n",
    "    def get_embeddings(self, texts):\n",
    "        return self.model.encode(texts)\n",
    "    \n",
    "embedding_ranker = EmbeddingRanker()\n",
    "embedding_ranker.train(train_catalog_df, train_queries_df, epochs=0)\n",
    "embedding_ranker.prerun(train_catalog_df)\n",
    "embedding_ranker.get_score({\"input_text\": \"Remote\"}, train_catalog_df)\n",
    "    \n",
    "trained_embedding_ranker_1 = EmbeddingRanker()\n",
    "trained_embedding_ranker_1.train(train_catalog_df, train_queries_df, epochs=1)\n",
    "trained_embedding_ranker_1.prerun(train_catalog_df)\n",
    "trained_embedding_ranker_1.get_score({\"input_text\": \"Remote\"}, train_catalog_df)\n",
    "\n",
    "bow_ranker = BoWRanker()\n",
    "bow_ranker.train(train_catalog_df, train_queries_df)\n",
    "bow_ranker.prerun(train_catalog_df)\n",
    "bow_ranker.get_score({\"input_text\": \"Remote\"}, train_catalog_df)\n",
    "\n",
    "tf_idf_ranker = TfidfRanker()\n",
    "tf_idf_ranker.train(train_catalog_df, train_queries_df)\n",
    "tf_idf_ranker.prerun(train_catalog_df)\n",
    "tf_idf_ranker.get_score({\"input_text\": \"Remote\"}, train_catalog_df)\n",
    "\n",
    "bm_25_ranker = BM25Ranker()\n",
    "bm_25_ranker.train(train_catalog_df, train_queries_df)\n",
    "bm_25_ranker.prerun(train_catalog_df)\n",
    "bm_25_ranker.get_score({\"input_text\": \"Remote\"}, train_catalog_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e9a41c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11470/11470 [00:07<00:00, 1454.92it/s]\n",
      "100%|██████████| 11470/11470 [00:08<00:00, 1306.27it/s]\n",
      "100%|██████████| 11470/11470 [00:12<00:00, 953.84it/s]\n",
      "  4%|▍         | 490/11470 [00:03<01:23, 131.15it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[151], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m metrics \u001b[38;5;241m=\u001b[39m evaluate(tf_idf_ranker, val_catalog_df, val_queries_df)\n\u001b[1;32m     37\u001b[0m report \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTF-IDF | Top 1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Top 10: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_10\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Top 100: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_100\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbm_25_ranker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_catalog_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_queries_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m report \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBM25   | Top 1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Top 10: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_10\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Top 100: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_100\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     40\u001b[0m metrics \u001b[38;5;241m=\u001b[39m evaluate(embedding_ranker, val_catalog_df, val_queries_df)\n",
      "Cell \u001b[0;32mIn[151], line 15\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(ranker, catalog_df, queries_df)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m input_query[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m input_query[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjudgment\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 15\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mranker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatalog_df\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     16\u001b[0m sorted_catalog \u001b[38;5;241m=\u001b[39m catalog_df\u001b[38;5;241m.\u001b[39miloc[np\u001b[38;5;241m.\u001b[39margsort(\u001b[38;5;241m-\u001b[39mscores)]\n\u001b[1;32m     17\u001b[0m rank \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(sorted_catalog[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcatalog_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m==\u001b[39m target_id)\n",
      "Cell \u001b[0;32mIn[150], line 124\u001b[0m, in \u001b[0;36mBM25Ranker.get_score\u001b[0;34m(self, query, catalog_df)\u001b[0m\n\u001b[1;32m    122\u001b[0m text \u001b[38;5;241m=\u001b[39m query[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m    123\u001b[0m query_vector \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 124\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm25\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_vector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m\"\u001b[39m: scores\n\u001b[1;32m    127\u001b[0m }\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/rank_bm25.py:118\u001b[0m, in \u001b[0;36mBM25Okapi.get_scores\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    116\u001b[0m doc_len \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoc_len)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m query:\n\u001b[0;32m--> 118\u001b[0m     q_freq \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdoc_freqs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     score \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midf\u001b[38;5;241m.\u001b[39mget(q) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m (q_freq \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\n\u001b[1;32m    120\u001b[0m                                        (q_freq \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk1 \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m*\u001b[39m doc_len \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgdl)))\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate(ranker, catalog_df, queries_df):\n",
    "    ranks = []\n",
    "    ranker.prerun(catalog_df)\n",
    "    for i,row in tqdm(queries_df.iterrows(), total=len(queries_df.index)):\n",
    "        input_query = dict(row)\n",
    "        target_id = input_query[\"match_id\"]\n",
    "        judgment = input_query[\"judgment\"]\n",
    "        \n",
    "        if judgment == True:\n",
    "            del input_query[\"match_id\"]\n",
    "            del input_query[\"judgment\"]\n",
    "            \n",
    "            scores = ranker.get_score(input_query, catalog_df)[\"scores\"]\n",
    "            sorted_catalog = catalog_df.iloc[np.argsort(-scores)]\n",
    "            rank = np.where(sorted_catalog[\"catalog_id\"].values == target_id)\n",
    "            rank = rank[0][0] # FIXME: This could file if target_id is not in the catalog_df, in that case, skip\n",
    "            ranks.append(rank)\n",
    "          \n",
    "    ranks = np.array(ranks)\n",
    "    return {\n",
    "        \"ranks\": ranks,\n",
    "        \"top_1\": sum(ranks < 1) / len(ranks),\n",
    "        \"top_10\": sum(ranks < 10) / len(ranks),\n",
    "        \"top_100\": sum(ranks < 100) / len(ranks),\n",
    "        \"top_1000\": sum(ranks < 1000) / len(ranks),\n",
    "    }\n",
    "\n",
    "report = \"\"\n",
    "\n",
    "metrics = evaluate(RandomRanker(), val_catalog_df, val_queries_df)\n",
    "report += (f'Random | Top 1: {metrics[\"top_1\"]} | Top 10: {metrics[\"top_10\"]} | Top 100: {metrics[\"top_100\"]}\\n')\n",
    "metrics = evaluate(bow_ranker, val_catalog_df, val_queries_df)\n",
    "report += (f'Bag of Words | Top 1: {metrics[\"top_1\"]} | Top 10: {metrics[\"top_10\"]} | Top 100: {metrics[\"top_100\"]}\\n')\n",
    "metrics = evaluate(tf_idf_ranker, val_catalog_df, val_queries_df)\n",
    "report += (f'TF-IDF | Top 1: {metrics[\"top_1\"]} | Top 10: {metrics[\"top_10\"]} | Top 100: {metrics[\"top_100\"]}\\n')\n",
    "metrics = evaluate(bm_25_ranker, val_catalog_df, val_queries_df)\n",
    "report += (f'BM25   | Top 1: {metrics[\"top_1\"]} | Top 10: {metrics[\"top_10\"]} | Top 100: {metrics[\"top_100\"]}\\n')\n",
    "metrics = evaluate(embedding_ranker, val_catalog_df, val_queries_df)\n",
    "report += (f'Sentance Transformer | Top 1: {metrics[\"top_1\"]} | Top 10: {metrics[\"top_10\"]} | Top 100: {metrics[\"top_100\"]}\\n')\n",
    "metrics = evaluate(trained_embedding_ranker_1, val_catalog_df, val_queries_df)\n",
    "report += (f'Fine Tuned Sentance Transformer | Top 1: {metrics[\"top_1\"]} | Top 10: {metrics[\"top_10\"]} | Top 100: {metrics[\"top_100\"]}\\n')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db17f112",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Save run\n",
    "with open(f'outputs/report_{DATASET_NAME}_{AUGMENTATION}_{int(time.time())}.txt', 'w') as f:\n",
    "    f.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30bf75fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:00<00:07, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranker 1 was better at matching \"Linn Energy (LINE) to Acquire US non-Core Oil, Gas Assets of Devon Energy\" to \"The Key to the Dow's Bull Market? Energy Stocks\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:00<00:06, 13.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranker 2 was better at matching \"China central bank to get tough on shadow financing\" to \"China Credit Gauge Declines as Officials Seek to Tame Debt Boom\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [00:02<00:05, 13.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranker 1 was better at matching \"Cbeyond Inc.: Birch Communications to Acquire Cbeyond\" to \"DA Davidson Does Not See Another Bidder Emerging for Cbeyond\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [00:03<00:04, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranker 1 was better at matching \"Who would you cast in the Morrissey biopic?\" to \"Morrissey Knocked To The Ground By Stage Invader At San Jose Concert\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [00:03<00:04, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranker 1 was better at matching \"Yum Brands Will Go Higher (YUM)\" to \"Not So Yum! Waffle Tacos Can't Stem Bleeding At KFC, Pizza Hut\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [00:04<00:02, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranker 2 was better at matching \"'Mad Men': Can you accept an optimistic, redemptive end for Don Draper?\" to \"'Mad Men' Review: Nip It in the Bud\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [00:04<00:02, 13.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranker 1 was better at matching \"Now, some carbon research even climate deniers can get bummed over\" to \"Climate Change Making Food Crops Less Nutritious, Research Finds\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [00:05<00:01, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranker 1 was better at matching \"Altitude Software Completes a Decade in Gartner's Magic Quadrant\" to \"Intel Security (McAfee), Positioned in the Leaders Quadrant for Secure Web\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 13.82it/s]\n"
     ]
    }
   ],
   "source": [
    "# def compare_rankers(ranker1, ranker2, catalog_df, queries_df, cutoff=10):\n",
    "#     ranks = []\n",
    "#     ranker1.prerun(catalog_df)\n",
    "#     ranker2.prerun(catalog_df)\n",
    "#     for i,row in tqdm(queries_df.iterrows(), total=len(queries_df.index)):\n",
    "#         input_query = dict(row)\n",
    "#         target_id = input_query[\"match_id\"]\n",
    "#         judgment = input_query[\"judgment\"]\n",
    "        \n",
    "#         if judgment == True:\n",
    "#             del input_query[\"match_id\"]\n",
    "#             del input_query[\"judgment\"]\n",
    "            \n",
    "#             scores1 = ranker1.get_score(input_query, catalog_df)[\"scores\"]\n",
    "#             scores2 = ranker2.get_score(input_query, catalog_df)[\"scores\"]\n",
    "#             sorted_catalog1 = catalog_df.iloc[np.argsort(-scores1)]\n",
    "#             sorted_catalog2 = catalog_df.iloc[np.argsort(-scores2)]\n",
    "#             rank1 = np.where(sorted_catalog1[\"catalog_id\"].values == target_id)\n",
    "#             rank1 = rank1[0][0]\n",
    "#             rank2 = np.where(sorted_catalog2[\"catalog_id\"].values == target_id)\n",
    "#             rank2 = rank2[0][0]\n",
    "            \n",
    "#             if rank1 < cutoff and rank2 > cutoff:\n",
    "#                 print(\"Ranker 1 was better at matching \\\"\" + input_query[\"input_text\"] + \"\\\" to \\\"\" + catalog_df[catalog_df[\"catalog_id\"] == target_id][\"text\"].values[0] + \"\\\"\")\n",
    "#             if rank2 < cutoff and rank1 > cutoff:\n",
    "#                 print(\"Ranker 2 was better at matching \\\"\" + input_query[\"input_text\"] + \"\\\" to \\\"\" + catalog_df[catalog_df[\"catalog_id\"] == target_id][\"text\"].values[0] + \"\\\"\")\n",
    "          \n",
    "# compare_rankers(tf_idf_ranker, trained_embedding_ranker_1, val_catalog_df, val_queries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26295015",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catalog_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Key to the Dow's Bull Market? Energy Stocks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dollar tumbles against yen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Google Drive price cuts signal start of Cloud ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Gov. Cuomo Unveils Plan To Combat HIV, AIDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>China Credit Gauge Declines as Officials Seek ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11465</th>\n",
       "      <td>11465</td>\n",
       "      <td>She's Not So Scary! Angelina Jolie Holds Hands...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11466</th>\n",
       "      <td>11466</td>\n",
       "      <td>Sea Turtle Amputee Swims Again with Jet-Like P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11467</th>\n",
       "      <td>11467</td>\n",
       "      <td>The Bistro cat feeder uses 'feline facial reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11468</th>\n",
       "      <td>11468</td>\n",
       "      <td>Ralph Lauren Debuts Fitness-tracking Tee in Ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11469</th>\n",
       "      <td>11469</td>\n",
       "      <td>Nick Cannon uses 'whiteface' to promote new album</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11470 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       catalog_id                                               text\n",
       "0               0    The Key to the Dow's Bull Market? Energy Stocks\n",
       "1               1                         Dollar tumbles against yen\n",
       "2               2  Google Drive price cuts signal start of Cloud ...\n",
       "3               3        Gov. Cuomo Unveils Plan To Combat HIV, AIDS\n",
       "4               4  China Credit Gauge Declines as Officials Seek ...\n",
       "...           ...                                                ...\n",
       "11465       11465  She's Not So Scary! Angelina Jolie Holds Hands...\n",
       "11466       11466  Sea Turtle Amputee Swims Again with Jet-Like P...\n",
       "11467       11467  The Bistro cat feeder uses 'feline facial reco...\n",
       "11468       11468  Ralph Lauren Debuts Fitness-tracking Tee in Ti...\n",
       "11469       11469  Nick Cannon uses 'whiteface' to promote new album\n",
       "\n",
       "[11470 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_catalog_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "555731d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = evaluate(bm_25_ranker, val_catalog_df, val_queries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b3bd63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/home/gebkab/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/home/gebkab/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nlpaug in /home/gebkab/.local/lib/python3.10/site-packages (1.1.11)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /home/gebkab/.local/lib/python3.10/site-packages (from nlpaug) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (1.5.2)\n",
      "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug) (2.29.0)\n",
      "Requirement already satisfied: gdown>=4.0.0 in /home/gebkab/.local/lib/python3.10/site-packages (from nlpaug) (4.7.1)\n",
      "Requirement already satisfied: filelock in /home/gebkab/.local/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug) (3.13.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.65.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->nlpaug) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->nlpaug) (2022.12.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.4.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/gebkab/.local/lib/python3.10/site-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -rotobuf (/home/gebkab/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy>=1.19.*; python_version >= \"3.7\". pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cbd15b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
