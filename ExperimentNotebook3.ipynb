{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd73905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATASET_NAME = \"covid-abstracts\"\n",
    "\n",
    "train_catalog_df = pd.read_csv(f\"data/{DATASET_NAME}/train_catalog.csv\")\n",
    "train_queries_df = pd.read_csv(f\"data/{DATASET_NAME}/train_queries.csv\")\n",
    "val_catalog_df = pd.read_csv(f\"data/{DATASET_NAME}/val_catalog.csv\")\n",
    "val_queries_df = pd.read_csv(f\"data/{DATASET_NAME}/val_queries.csv\")\n",
    "print(f\"Loaded {len(train_catalog_df.index)} Documents\")\n",
    "print(f\"Loaded {len(train_queries_df.index)} Judgments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb649d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_catalog_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c65d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class RandomRanker:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self, catalog_df, queries_df):\n",
    "        pass\n",
    "    \n",
    "    def prerun(self, catalog_df):\n",
    "        pass\n",
    "    \n",
    "    def get_score(self, query, catalog_df):\n",
    "        text = query[\"input_text\"]\n",
    "        return {\n",
    "            \"scores\": np.random.uniform(0,1,size=len(catalog_df))\n",
    "        }\n",
    "    \n",
    "def levenshtein_distance(word1, word2):\n",
    "    if len(word1) < len(word2):\n",
    "        return levenshtein_distance(word2, word1)\n",
    "\n",
    "    if len(word2) == 0:\n",
    "        return len(word1)\n",
    "\n",
    "    previous_row = range(len(word2) + 1)\n",
    "\n",
    "    for i, c1 in enumerate(word1):\n",
    "        current_row = [i + 1]\n",
    "\n",
    "        for j, c2 in enumerate(word2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "\n",
    "        previous_row = current_row\n",
    "\n",
    "    return previous_row[-1]\n",
    "    \n",
    "\n",
    "def normalized_levenshtein_distance(word1, word2):\n",
    "    distance = levenshtein_distance(word1, word2)\n",
    "    max_length = max(len(word1), len(word2))\n",
    "    return distance / max_length\n",
    "\n",
    "    \n",
    "class LevensteinRanker:\n",
    "    def __init__(self):\n",
    "        print(\"Wanring! This is a slow ranker\")\n",
    "        pass\n",
    "    \n",
    "    def train(self, catalog_df, queries_df):\n",
    "        pass\n",
    "    \n",
    "    def prerun(self, catalog_df):\n",
    "        pass\n",
    "    \n",
    "    def get_score(self, query, catalog_df):\n",
    "        text = query[\"input_text\"]\n",
    "        \n",
    "        return {\n",
    "            \"scores\": catalog_df[\"text\"].apply(lambda x: -normalized_levenshtein_distance(x, text)).values\n",
    "        }\n",
    "    \n",
    "class TfidfRanker:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(token_pattern=r'\\b\\w+\\b', lowercase=True)\n",
    "\n",
    "    def train(self, catalog_df, queries_df):\n",
    "        self.vectorizer.fit(catalog_df['text'].str.lower())\n",
    "\n",
    "    def prerun(self, catalog_df):\n",
    "        pass\n",
    "        \n",
    "    def get_score(self, query, catalog_df):\n",
    "        text = query[\"input_text\"].lower()\n",
    "        tfidf_matrix = self.vectorizer.transform(catalog_df['text'].str.lower())\n",
    "        query_vector = self.vectorizer.transform([text])\n",
    "        scores = (tfidf_matrix * query_vector.T).toarray()\n",
    "        return {\n",
    "            \"scores\": scores.flatten()\n",
    "        }\n",
    "    \n",
    "class BM25Ranker:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def train(self, catalog_df, queries_df):\n",
    "        pass\n",
    "        \n",
    "    def prerun(self, catalog_df):\n",
    "        corpus = catalog_df['text'].str.lower().tolist()\n",
    "        tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "    def get_score(self, query, catalog_df):\n",
    "        text = query[\"input_text\"].lower()\n",
    "        query_vector = text.split(\" \")\n",
    "        scores = self.bm25.get_scores(query_vector)\n",
    "        return {\n",
    "            \"scores\": scores\n",
    "        }\n",
    "    \n",
    "class EmbeddingRanker:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def train(self, catalog_df, queries_df, epochs=0):\n",
    "        if epochs != 0:\n",
    "            # Prepare the data for training\n",
    "            examples = []\n",
    "            for _, row in queries_df.iterrows():\n",
    "                text = row['input_text']\n",
    "                positive_id = row['match_id']\n",
    "                try:\n",
    "                    positive_text = catalog_df.loc[catalog_df['catalog_id'] == positive_id, 'text'].values[0]\n",
    "                    negative_ids = catalog_df.loc[catalog_df['catalog_id'] != positive_id, 'catalog_id'].sample(n=1).values\n",
    "                    negative_text = catalog_df.loc[catalog_df['catalog_id'] == negative_ids[0], 'text'].values[0]\n",
    "                    examples.append(InputExample(texts=[text, positive_text, negative_text]))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            print(f\"{len(examples)} Examples Found\")\n",
    "\n",
    "            train_dataloader = DataLoader(examples, shuffle=True, batch_size=16)\n",
    "            train_loss = losses.TripletLoss(self.model)\n",
    "\n",
    "            self.model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=epochs)\n",
    "\n",
    "    def prerun(self, catalog_df):\n",
    "        self.corpus = catalog_df['text'].str.lower().tolist()\n",
    "        self.corpus_embeddings = self.get_embeddings(self.corpus)\n",
    "\n",
    "    def get_score(self, query, catalog_df):\n",
    "        query_embedding = self.get_embeddings([query[\"input_text\"]])\n",
    "        scores = cosine_similarity(query_embedding, self.corpus_embeddings)\n",
    "        return {\n",
    "            \"scores\": scores.flatten()\n",
    "        }\n",
    "\n",
    "    def get_embeddings(self, texts):\n",
    "        return self.model.encode(texts)\n",
    "    \n",
    "embedding_ranker = EmbeddingRanker()\n",
    "embedding_ranker.train(train_catalog_df, train_queries_df, epochs=0)\n",
    "embedding_ranker.prerun(train_catalog_df)\n",
    "embedding_ranker.get_score({\"input_text\": \"Remote\"}, train_catalog_df)\n",
    "    \n",
    "trained_embedding_ranker = EmbeddingRanker()\n",
    "trained_embedding_ranker.train(train_catalog_df, train_queries_df, epochs=1)\n",
    "trained_embedding_ranker.prerun(train_catalog_df)\n",
    "trained_embedding_ranker.get_score({\"input_text\": \"Remote\"}, train_catalog_df)\n",
    "    \n",
    "tf_idf_ranker = TfidfRanker()\n",
    "tf_idf_ranker.train(train_catalog_df, train_queries_df)\n",
    "tf_idf_ranker.prerun(train_catalog_df)\n",
    "tf_idf_ranker.get_score({\"input_text\": \"Remote\"}, train_catalog_df)\n",
    "\n",
    "bm_25_ranker = BM25Ranker()\n",
    "bm_25_ranker.train(train_catalog_df, train_queries_df)\n",
    "bm_25_ranker.prerun(train_catalog_df)\n",
    "bm_25_ranker.get_score({\"input_text\": \"Remote\"}, train_catalog_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a9358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate(ranker, catalog_df, queries_df):\n",
    "    ranks = []\n",
    "    ranker.prerun(catalog_df)\n",
    "    for i,row in tqdm(queries_df.iterrows(), total=len(queries_df.index)):\n",
    "        input_query = dict(row)\n",
    "        target_id = input_query[\"match_id\"]\n",
    "        judgment = input_query[\"judgment\"]\n",
    "        \n",
    "        if judgment == True:\n",
    "            del input_query[\"match_id\"]\n",
    "            del input_query[\"judgment\"]\n",
    "            \n",
    "            scores = ranker.get_score(input_query, catalog_df)[\"scores\"]\n",
    "            sorted_catalog = catalog_df.iloc[np.argsort(-scores)]\n",
    "            rank = np.where(sorted_catalog[\"catalog_id\"].values == target_id)\n",
    "            rank = rank[0][0] # FIXME: This could file if target_id is not in the catalog_df, in that case, skip\n",
    "            ranks.append(rank)\n",
    "          \n",
    "    ranks = np.array(ranks)\n",
    "    return {\n",
    "        \"ranks\": ranks,\n",
    "        \"top_1\": sum(ranks < 1) / len(ranks),\n",
    "        \"top_10\": sum(ranks < 10) / len(ranks),\n",
    "        \"top_100\": sum(ranks < 100) / len(ranks),\n",
    "        \"top_1000\": sum(ranks < 1000) / len(ranks),\n",
    "    }\n",
    "\n",
    "print(f'Top 10 Random: {evaluate(RandomRanker(), val_catalog_df, val_queries_df)[\"top_10\"]}')\n",
    "print(f'Top 10 TF-IDF: {evaluate(tf_idf_ranker, val_catalog_df, val_queries_df)[\"top_10\"]}')\n",
    "print(f'Top 10 BM-25: {evaluate(bm_25_ranker, val_catalog_df, val_queries_df)[\"top_10\"]}')\n",
    "print(f'Top 10 Sentence Transformer: {evaluate(embedding_ranker, val_catalog_df, val_queries_df)[\"top_10\"]}')\n",
    "print(f'Top 10 Fine Tuned Sentence Transformer: {evaluate(trained_embedding_ranker, val_catalog_df, val_queries_df)[\"top_10\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dde2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_catalog_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfee7122",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate(bm_25_ranker, val_catalog_df, val_queries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbba097f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
